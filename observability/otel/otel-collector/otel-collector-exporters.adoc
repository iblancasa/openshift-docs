:_mod-docs-content-type: ASSEMBLY
[id="otel-collector-exporters"]
= Exporters
include::_attributes/common-attributes.adoc[]
:context: otel-collector-exporters

toc::[]

Exporters send data to one or more back ends or destinations. An exporter can be push or pull based. By default, no exporters are configured. One or more exporters must be configured. Exporters can support one or more data sources. Exporters might be used with their default settings, but many exporters require configuration to specify at least the destination and security settings.

[id="kafka-exporter_{context}"]
== Kafka Exporter

The Kafka Exporter exports logs, metrics, and traces to Kafka. This exporter uses a synchronous producer that blocks and does not batch messages. You must use it with batch and queued retry processors for higher throughput and resiliency.

:FeatureName: The Kafka Exporter
include::snippets/technology-preview.adoc[]

.OpenTelemetry Collector custom resource with an enabled Kafka Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      kafka:
        brokers: ["localhost:9092"]
        protocol_version: 2.0.0
        topic: otlp_spans
        auth:
          plain_text:
            username: example
            password: example
          tls:
            ca_file: ca.pem
            cert_file: cert.pem
            key_file: key.pem
            insecure: false
            server_name_override: kafka.example.corp
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 1000
        producer:
          max_message_bytes: 1000000
          required_acks: 1
          compression: none
          flush_max_messages: 0
    service:
      pipelines:
        traces:
          exporters: [kafka]
# ...
----

.Parameters used by the Kafka Exporter
[options="header"]
[cols="a,a,a"]
|===
|Parameter |Description |Default

|`brokers`
|The list of Kafka brokers
|`["localhost:9092"]`

|`protocol_version`
|The Kafka protocol version. This is a required field
|`2.0.0`

|`topic`
|The name of the Kafka topic to read from.
|`otlp_spans` for traces, `otlp_metrics` for metrics, and `otlp_logs` for logs

|`auth.plain_text`
|The plain text authentication configuration. If omitted, plain text authentication is disabled
|N/A

|`auth.tls`
|The client-side TLS configuration, defining paths to the TLS certificates. If omitted, TLS authentication is disabled
|N/A

|`auth.tls.insecure`
|Disables verifying the server's certificate chain and host name
|`false`

|`auth.tls.server_name_override`
|ServerName indicates the name of the server requested by the client to support virtual hosting
|`kafka.example.corp`

|`retry_on_failure.enabled`
|Settings for the retry mechanism
|`true`

|`retry_on_failure.initial_interval`
|Time to wait after the first failure before retrying
|`5s`

|`retry_on_failure.max_interval`
|Upper bound on backoff
|`30s`

|`retry_on_failure.max_elapsed_time`
|Maximum time spent trying to send a batch. A value of `0` means retries never stop
|`300s`

|`sending_queue.enabled`
|Settings for the sending queue
|`true`

|`sending_queue.num_consumers`
|Number of consumers that dequeue batches
|`10`

|`sending_queue.queue_size`
|Maximum number of batches kept in memory before dropping
|`1000`

|`producer.max_message_bytes`
|The maximum allowed message size in bytes
|`1000000`

|`producer.required_acks`
|Determines when a message is considered transmitted
|`1`

|`producer.compression`
|Specifies the compression method used when producing messages to Kafka. Options include `none`, `gzip`, `snappy`, `lz4`, and `zstd`
|`none`

|`producer.flush_max_messages`
|The maximum number of messages the producer can send in a single request to the broker
|`0`
|===

=== Troubleshooting the Kafka Exporter

If you encounter issues with the Kafka Exporter, the following troubleshooting steps can help diagnose and resolve common problems.

==== Messages fail to reach the Kafka topic

If messages are not being exported to the Kafka topic, check the following:

.Procedure

- Verify Kafka broker connection: ensure the `brokers` parameter is correctly configured with the correct Kafka broker addresses. Confirm that the Kafka broker is reachable from the OpenTelemetry Collector instance.
+
- Check the `topic`: ensure the Kafka topic name specified in the `topic` field matches an existing topic in the Kafka server. The default topics are `otlp_spans`, `otlp_metrics`, and `otlp_logs`.
+
- Ensure correct pipeline setup: confirm that the Kafka Exporter is properly configured in the `service.pipelines` section of the OpenTelemetry Collector configuration.

==== High latency or performance issues

If the Kafka Exporter is experiencing high latency or performance issues, consider the following:

.Procedure

- Review the `sending_queue.num_consumers` parameter value: increasing the number of consumers can improve throughput if the default value is insufficient for the telemetry data volume.
+
- Check `queue_size`: ensure that the `sending_queue.queue_size` is large enough to handle the volume of telemetry data without dropping messages.
+
- Optimize retry settings: adjust the `retry_on_failure` parameters to optimize the retry intervals (`initial_interval`, `max_interval`) and the total time spent retrying (`max_elapsed_time`). Higher intervals may contribute to increased latency if retries are frequent.

==== Authentication failures

If authentication errors occur, verify the following:

.Procedure

- Plain text authentication configuration: if using plain text authentication, ensure that the `auth.plain_text.username` and `auth.plain_text.password` fields are correctly configured with valid credentials.
+
- TLS configuration: if using TLS, confirm that the paths to the TLS certificates (`auth.tls.ca_file`, `auth.tls.cert_file`, `auth.tls.key_file`) are correct and accessible. Verify that `auth.tls.insecure` is set to `false` if you want to enforce certificate validation.
+
- Server name mismatch: ensure that `auth.tls.server_name_override` is set to the correct server name. A mismatch between the server name and the certificate can cause authentication errors.

==== Message size exceeds limit

If messages fail to send because they exceed the allowed size, check the following:

.Procedure

- Increase `max_message_bytes`: the `producer.max_message_bytes` parameter controls the maximum size of messages sent to Kafka. Increase this value if your telemetry data requires larger message sizes. The default is 1 MB (`1000000` bytes).
+
- Enable compression: consider setting `producer.compression` to a compression algorithm like `gzip` or `lz4` to reduce the size of messages sent to Kafka.

[id="otlp-exporter_{context}"]
== OTLP Exporter

The OTLP gRPC Exporter exports traces and metrics by using the OpenTelemetry protocol (OTLP).

.OpenTelemetry Collector custom resource with an enabled OTLP Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      otlp:
        endpoint: tempo-ingester:4317 # <1>
        tls: # <2>
          ca_file: ca.pem
          cert_file: cert.pem
          key_file: key.pem
          insecure: false # <3>
          insecure_skip_verify: false # # <4>
          reload_interval: 1h # <5>
          server_name_override: <name> # <6>
        headers: # <7>
          X-Scope-OrgID: "dev"
    service:
      pipelines:
        traces:
          exporters: [otlp]
        metrics:
          exporters: [otlp]
# ...
----
<1> The OTLP gRPC endpoint. If the `+https://+` scheme is used, then client transport security is enabled and overrides the `insecure` setting in the `tls`.
<2> The client-side TLS configuration. Defines paths to TLS certificates.
<3> Disables client transport security when set to `true`. The default value is `false` by default.
<4> Skips verifying the certificate when set to `true`. The default value is `false`.
<5> Specifies the time interval at which the certificate is reloaded. If the value is not set, the certificate is never reloaded. The `reload_interval` accepts a string containing valid units of time such as `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.
<6> Overrides the virtual host name of authority such as the authority header field in requests. You can use this for testing.
<7> Headers are sent for every request performed during an established connection.

[id="otlp-http-exporter_{context}"]
== OTLP HTTP Exporter

The OTLP HTTP Exporter exports traces and metrics by using the OpenTelemetry protocol (OTLP).

.OpenTelemetry Collector custom resource with an enabled OTLP Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      otlphttp:
        endpoint: http://tempo-ingester:4318 # <1>
        tls: # <2>
        headers: # <3>
          X-Scope-OrgID: "dev"
        disable_keep_alives: false <4>

    service:
      pipelines:
        traces:
          exporters: [otlphttp]
        metrics:
          exporters: [otlphttp]
# ...
----
<1> The OTLP HTTP endpoint. If the `+https://+` scheme is used, then client transport security is enabled and overrides the `insecure` setting in the `tls`.
<2> The client side TLS configuration. Defines paths to TLS certificates.
<3> Headers are sent in every HTTP request.
<4> If true, disables HTTP keep-alives. It will only use the connection to the server for a single HTTP request.

[id="debug-exporter_{context}"]
== Debug Exporter

The Debug Exporter prints traces and metrics to the standard output.

.OpenTelemetry Collector custom resource with an enabled Debug Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      debug:
        verbosity: detailed # <1>
    service:
      pipelines:
        traces:
          exporters: [logging]
        metrics:
          exporters: [logging]
# ...
----
<1> Verbosity of the debug export: `detailed` or `normal` or `basic`. When set to `detailed`, pipeline data is verbosely logged. Defaults to `normal`.

[id="load-balancing-exporter_{context}"]
== Load Balancing Exporter

The Load Balancing Exporter consistently exports spans, metrics, and logs according to the `routing_key` configuration.

:FeatureName: The Load Balancing Exporter
include::snippets/technology-preview.adoc[leveloffset=+1]

.OpenTelemetry Collector custom resource with an enabled Load Balancing Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      loadbalancing:
        routing_key: "service" # <1>
        protocol:
          otlp: # <2>
            timeout: 1s
        resolver: # <3>
          static: # <4>
            hostnames:
            - backend-1:4317
            - backend-2:4317
          dns: # <5>
            hostname: otelcol-headless.observability.svc.cluster.local
          k8s: # <6>
            service: lb-svc.kube-public
            ports:
              - 15317
              - 16317
# ...
----
<1> The `routing_key: service` exports spans for the same service name to the same Collector instance to provide accurate aggregation. The `routing_key: traceID` exports spans based on their `traceID`. The implicit default is `traceID` based routing.
<2> The OTLP is the only supported load-balancing protocol. All options of the OTLP exporter are supported.
<3> You can configure only one resolver.
<4> The static resolver distributes the load across the listed endpoints.
<5> You can use the DNS resolver only with a Kubernetes headless service.
<6> The Kubernetes resolver is recommended.

[id="prometheus-exporter_{context}"]
== Prometheus Exporter

The Prometheus Exporter exports metrics in the Prometheus or OpenMetrics formats.

:FeatureName: The Prometheus Exporter
include::snippets/technology-preview.adoc[]

.OpenTelemetry Collector custom resource with an enabled Prometheus Exporter
[source,yaml]
----
# ...
  ports:
  - name: promexporter # <1>
    port: 8889
    protocol: TCP
  config: |
    exporters:
      prometheus:
        endpoint: 0.0.0.0:8889 # <2>
        tls: # <3>
          ca_file: ca.pem
          cert_file: cert.pem
          key_file: key.pem
        namespace: prefix # <4>
        const_labels: # <5>
          label1: value1
        enable_open_metrics: true # <6>
        resource_to_telemetry_conversion: # <7>
          enabled: true
        metric_expiration: 180m # <8>
        add_metric_suffixes: false # <9>
    service:
      pipelines:
        metrics:
          exporters: [prometheus]
# ...
----
<1> Exposes the Prometheus port from the Collector pod and service. You can enable scraping of metrics by Prometheus by using the port name in `ServiceMonitor` or `PodMonitor` custom resource.
<2> The network endpoint where the metrics are exposed.
<3> The server-side TLS configuration. Defines paths to TLS certificates.
<4> If set, exports metrics under the provided value. No default.
<5> Key-value pair labels that are applied for every exported metric. No default.
<6> If `true`, metrics are exported using the OpenMetrics format. Exemplars are only exported in the OpenMetrics format and only for histogram and monotonic sum metrics such as `counter`. Disabled by default.
<7> If `enabled` is `true`, all the resource attributes are converted to metric labels by default. Disabled by default.
<8> Defines how long metrics are exposed without updates. The default is `5m`.
<9> Adds the metrics types and units suffixes. Must be disabled if the monitor tab in Jaeger console is enabled. The default is `true`.

[id="prometheus-remote-write-exporter_{context}"]
== Prometheus Remote Write Exporter

The Prometheus Remote Write Exporter exports metrics to compatible back ends.

:FeatureName: The Prometheus Remote Write Exporter
include::snippets/technology-preview.adoc[]

.OpenTelemetry Collector custom resource with an enabled Prometheus Remote Write Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      prometheusremotewrite:
        endpoint: "https://my-prometheus:7900/api/v1/push" # <1>
        tls: # <2>
          ca_file: ca.pem
          cert_file: cert.pem
          key_file: key.pem
        target_info: true # <3>
        export_created_metric: true # <4>
        max_batch_size_bytes: 3000000 # <5>
    service:
      pipelines:
        metrics:
          exporters: [prometheusremotewrite]
# ...
----
<1> Endpoint for sending the metrics.
<2> Server-side TLS configuration. Defines paths to TLS certificates.
<3> When set to `true`, creates a `target_info` metric for each resource metric.
<4> When set to `true`, exports a `_created` metric for the Summary, Histogram, and Monotonic Sum metric points.
<5> Maximum size of the batch of samples that is sent to the remote write endpoint. Exceeding this value results in batch splitting. The default value is `3000000`, which is approximately 2.861 megabytes.

[WARNING]
====
* This exporter drops non-cumulative monotonic, histogram, and summary OTLP metrics.

* You must enable the `--web.enable-remote-write-receiver` feature flag on the remote Prometheus instance. Without it, pushing the metrics to the instance using this exporter fails.
====

[role="_additional-resources"]
[id="additional-resources_otel-collector-exporters_{context}"]
== Additional resources
* link:https://opentelemetry.io/docs/specs/otlp/[OpenTelemetry Protocol (OTLP) documentation]
