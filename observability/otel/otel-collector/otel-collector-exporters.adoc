:_mod-docs-content-type: ASSEMBLY
[id="otel-collector-exporters"]
= Exporters
include::_attributes/common-attributes.adoc[]
:context: otel-collector-exporters

toc::[]

Exporters send data to one or more back ends or destinations. An exporter can be push or pull based. By default, no exporters are configured. One or more exporters must be configured. Exporters can support one or more data sources. Exporters might be used with their default settings, but many exporters require configuration to specify at least the destination and security settings.

[id="kafka-exporter_{context}"]
== Kafka Exporter

The Kafka Exporter exports logs, metrics, and traces to Kafka. This exporter uses a synchronous producer that blocks and does not batch messages. You must use it with batch and queued retry processors for higher throughput and resiliency.

:FeatureName: Kafka Exporter
include::snippets/technology-preview.adoc[]

.OpenTelemetry Collector custom resource with an enabled Kafka Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      kafka:
        brokers: ["localhost:9092"]
        protocol_version: 2.0.0
        topic: otlp_spans
        auth:
          plain_text:
            username: example
            password: example
          tls:
            ca_file: ca.pem
            cert_file: cert.pem
            key_file: key.pem
            insecure: false
            server_name_override: kafka.example.corp
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 1000
        producer:
          max_message_bytes: 1000000
          required_acks: 1
          compression: none
          flush_max_messages: 0
    service:
      pipelines:
        traces:
          exporters: [kafka]
# ...
----

.Parameters used by the Kafka Exporter
[options="header"]
[cols="a,a,a"]
|===
|Parameter |Description |Default

|`brokers`
|The list of Kafka brokers.
|`["localhost:9092"]`

|`protocol_version`
|The Kafka protocol version. This is a required field.
|`2.0.0`

|`topic`
|The name of the Kafka topic to read from.
|`otlp_spans` for traces, `otlp_metrics` for metrics, and `otlp_logs` for logs

|`auth.plain_text`
|The plain text authentication configuration. If omitted, plain text authentication is disabled.
|N/A

|`auth.tls`
|The client-side TLS configuration, defining paths to the TLS certificates. If omitted, TLS authentication is disabled.
|N/A

|`auth.tls.insecure`
|Disables verifying the server's certificate chain and host name.
|`false`

|`auth.tls.server_name_override`
|ServerName indicates the name of the server requested by the client to support virtual hosting.
|`kafka.example.corp`

|`retry_on_failure.enabled`
|Settings for the retry mechanism.
|`true`

|`retry_on_failure.initial_interval`
|Time to wait after the first failure before retrying.
|`5s`

|`retry_on_failure.max_interval`
|Upper bound on backoff.
|`30s`

|`retry_on_failure.max_elapsed_time`
|Maximum amount of time spent trying to send a batch. `0` means retries never stop.
|`300s`

|`sending_queue.enabled`
|Settings for the sending queue.
|`true`

|`sending_queue.num_consumers`
|Number of consumers that dequeue batches.
|`10`

|`sending_queue.queue_size`
|Maximum number of batches kept in memory before dropping.
|`1000`

|`producer.max_message_bytes`
|The maximum allowed message size in bytes.
|`1000000`

|`producer.required_acks`
|Determines when a message is considered transmitted.
|`1`

|`producer.compression`
|Specifies the compression method used when producing messages to Kafka. Options include `none`, `gzip`, `snappy`, `lz4`, and `zstd`.
|`none`

|`producer.flush_max_messages`
|The maximum number of messages the producer can send in a single request to the broker.
|`0`
|===

=== Troubleshooting the Kafka Exporter

If you encounter issues with the Kafka Exporter, the following troubleshooting steps can help diagnose and resolve common problems.

==== Messages not reaching the Kafka topic

If messages are not being exported to the Kafka topic, check the following:

.Procedure

- Verify Kafka broker connection: ensure the `brokers` parameter is correctly configured with the correct Kafka broker addresses. Confirm that the Kafka broker is reachable from the OpenTelemetry Collector instance.
+
- Check the `topic`: ensure the Kafka topic name specified in the `topic` field matches an existing topic in the Kafka server. The default topics are `otlp_spans`, `otlp_metrics`, and `otlp_logs`.
+
- Ensure correct pipeline setup: confirm that the Kafka Exporter is properly configured in the `service.pipelines` section of the OpenTelemetry Collector configuration.

==== High latency or performance issues

If the Kafka Exporter is experiencing high latency or performance issues, consider the following:

.Procedure

- Increase `num_consumers`: review the `sending_queue.num_consumers` parameter. Increasing the number of consumers might improve throughput, especially if the default value is insufficient for the volume of telemetry data.
+
- Check `queue_size`: ensure that the `sending_queue.queue_size` is large enough to handle the volume of telemetry data without dropping messages.
+
- Optimize retry settings: adjust the `retry_on_failure` parameters to optimize the retry intervals (`initial_interval`, `max_interval`) and the total time spent retrying (`max_elapsed_time`). Higher intervals may contribute to increased latency if retries are frequent.

==== Authentication failures

If authentication errors occur, verify the following:

.Procedure

- Plain text authentication configuration: if using plain text authentication, ensure that the `auth.plain_text.username` and `auth.plain_text.password` fields are correctly configured with valid credentials.
+
- TLS configuration: if using TLS, confirm that the paths to the TLS certificates (`auth.tls.ca_file`, `auth.tls.cert_file`, `auth.tls.key_file`) are correct and accessible. Verify that `auth.tls.insecure` is set to `false` if you want to enforce certificate validation.
+
- Server name mismatch: ensure that `auth.tls.server_name_override` is set to the correct server name. A mismatch between the server name and the certificate can cause authentication errors.

==== Message size exceeds limit

If messages fail to send because they exceed the allowed size, check the following:

.Procedure

- Increase `max_message_bytes`: the `producer.max_message_bytes` parameter controls the maximum size of messages sent to Kafka. Increase this value if your telemetry data requires larger message sizes. The default is 1 MB (`1000000` bytes).
+
- Enable compression: consider setting `producer.compression` to a compression algorithm like `gzip` or `lz4` to reduce the size of messages sent to Kafka.


[id="load-balancing-exporter_{context}"]
== Load Balancing Exporter

The Load Balancing Exporter consistently exports spans, metrics, and logs according to the `routing_key` configuration.

:FeatureName: Load Balancing Exporter
include::snippets/technology-preview.adoc[leveloffset=+1]

.OpenTelemetry Collector custom resource with an enabled Load Balancing Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      loadbalancing:
        routing_key: "service"
        protocol:
          otlp: # <1>
            timeout: 1s
        resolver: # <2>
          static: # <3>
            hostnames:
            - backend-1:4317
            - backend-2:4317
          dns: # <4>
            hostname: otelcol-headless.observability.svc.cluster.local
          k8s: # <5>
            service: lb-svc.kube-public
            ports:
              - 15317
              - 16317
# ...
----
<1> The OTLP protocol is supported for load balancing.
<2> Only one resolver can be configured.
<3> The static resolver assigns load based on a fixed list of backends.
<4> The DNS resolver is compatible with Kubernetes headless services.
<5> The Kubernetes resolver is recommended for dynamic environments.

This exporter will export signals (spans, metrics, logs) based on the configured `routing_key`.

.The supported `routing_key` options and their usage
[cols="1,2", options="header"]
|===
| `routing_key` | Can be used for 
| `service`     | logs, spans, metrics 
| `traceID`     | logs, spans
| `resource`    | metrics
| `metric`      | metrics
| `streamID`    | metrics
|===

If no `routing_key` is specified, the default behavior is `traceID` for traces and `service` for metrics. This ensures that signals from the same trace or service are sent to the same backend.

The load balancing exporter requires backend information, either via a static list of backends or a DNS-based resolver (e.g., a Kubernetes headless service). DNS resolution periodically updates the backend list.

The exporter makes routing decisions based on the trace ID or service name. Backend load is not taken into consideration, but load distribution is expected to be stable, with less than 5% deviation.

This exporter is particularly useful for backends with tail-based samplers or red-metrics-collectors, which need visibility into full traces.

When the backend list changes, some signals are rerouted to different backends. The number of rerouted "routes" is approximately `R/N`, where:

* `R` is the total number of routes (trace IDs or service names mapped to a backend).
* `N` is the total number of backends.

This load balancer supports service name-based routing for traces. In scenarios where spanmetrics connectors generate metrics and push them to Prometheus, routing based on `service` avoids label collisions caused by multiple collectors seeing the same `service+operation` labels.

The following metrics are generated when this exporter is in use:

- `otelcol_loadbalancer_num_resolutions`: Total number of resolutions performed by the resolver (tagged by resolver and success status).
- `otelcol_loadbalancer_num_backends`: Number of active backends. For static resolvers, this should match the configuration.
- `otelcol_loadbalancer_num_backend_updates`: Number of backend list updates. High update frequency may indicate an issue with the load balancer.
- `otelcol_loadbalancer_backend_latency`: Measures backend latency.
- `otelcol_loadbalancer_backend_outcome`: Tracks the success or failure (success=true|false) for each backend endpoint.

The `loadbalancingexporter` creates an exporter per backend, conforming to the configured send queue and retry mechanisms. However, failed delivery to an endpoint can result in data loss if the target remains unavailable after retries are exhausted.

* When using the `static` resolver, all telemetry routed to an unavailable backend will fail until the backend is restored or removed.
* The `dns` and `k8s` resolvers will eventually update the list of available backends. The `k8s` resolver is generally faster to react than the `dns` resolver, but a temporary mismatch between the exporter's view and the actual topology may occur.


.Parameters used by the Load Balancing Exporter
[options="header"]
[cols="a,a,a"]
|===
|Parameter |Description |Default

|`routing_key`
|Determines how the load balancer distributes signals like spans, metrics, and logs. Options include `service`, `traceID`, `metric`, `resource`, and `streamID`.
|`traceID`

|`protocol.otlp`
|OTLP configuration fields are supported.
|N/A

|`resolver`
|Only one resolver can be configured.
|N/A

|`resolver.static.hostnames`
|The static resolver assigns load based on a fixed list of backends.
|N/A

|`resolver.dns.hostname`
|The DNS resolver is compatible with Kubernetes headless services.
|N/A

|`resolver.k8s.service`
|Specifies the Kubernetes service for the Kubernetes resolver.
|N/A

|`resolver.k8s.ports`
|Lists the ports for the Kubernetes resolver.
|N/A
|===


[id="otlp-exporter_{context}"]
== OTLP Exporter

The OTLP gRPC Exporter exports traces and metrics by using the OpenTelemetry protocol (OTLP).

.OpenTelemetry Collector custom resource with an enabled OTLP Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      otlp:
        endpoint: tempo-ingester:4317 # <1>
        tls:
          ca_file: ca.pem
          cert_file: cert.pem
          key_file: key.pem
          insecure: false
          insecure_skip_verify: false
          reload_interval: 1h
          server_name_override: ""
        headers:
          X-Scope-OrgID: "dev" # <2>
        compression:
        keepalive:
          permit_without_stream: false
          time:
          timeout:
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 1000
        timeout: 5s
        write_buffer_size: 524288
    service:
      pipelines:
        traces:
          exporters: [otlp]
        metrics:
          exporters: [otlp]
# ...
----
<1> In this example, we are exporting traces to a Tempo instance.
<2> This will set the "X-Scope-OrgID" header in the exported telemetry data. `X-Scope-OrgID` header is used to identify the tenant.

.Parameters used by the OTLP Exporter
[options="header"]
[cols="a,a,a"]
|===
|Parameter |Description |Default

|`endpoint`
|The OTLP gRPC endpoint. If the `https://` scheme is used, client transport security is enabled and overrides the `insecure` setting in `tls`.
|N/A

|`tls`
|The client-side TLS configuration, defining paths to TLS certificates.
|N/A

|`tls.insecure`
|Disables client transport security when set to `true`.
|`false`

|`tls.insecure_skip_verify`
|Skips verifying the certificate when set to `true`.
|`false`

|`tls.reload_interval`
|Specifies the time interval at which the certificate is reloaded. Accepts valid units of time such as `ns`, `us`, `ms`, `s`, `m`, and `h`.
|N/A

|`tls.server_name_override`
|Overrides the virtual host name of authority such as the authority header field in requests. Useful for testing.
|N/A

|`headers`
|Headers sent for every request performed during an established connection.
|N/A

|`compression`
|Compression type to use. Supported values: `gzip`, `snappy`, `zstd`, and `none`.
|`gzip`

|`keepalive.permit_without_stream`
|If set to `true`, the client sends keepalive pings even when there are no active RPCs.
|`false`

|`keepalive.time`
|Duration of inactivity after which the client sends a ping to the server (nanoseconds).
|`10000000000`

|`keepalive.timeout`
|Time the client waits after sending a keepalive ping before closing the connection if no activity is detected (nanoseconds).
|`10000000000`

|`retry_on_failure.enabled`
|Settings for the retry mechanism.
|`true`

|`retry_on_failure.initial_interval`
|Time to wait after the first failure before retrying.
|`5s`

|`retry_on_failure.max_interval`
|Upper bound on backoff.
|`30s`

|`retry_on_failure.max_elapsed_time`
|Maximum amount of time spent trying to send a batch. `0` means retries never stop.
|`300s`

|`sending_queue.enabled`
|Settings for the sending queue.
|`true`

|`sending_queue.num_consumers`
|Number of consumers that dequeue batches.
|`10`

|`sending_queue.queue_size`
|Maximum number of batches kept in memory before dropping.
|`1000`

|`timeout`
|Time to wait per individual attempt to send data.
|`5s`

|`write_buffer_size`
|The size of write buffer in bytes.
|`524288`
|===


=== Troubleshooting the OTLP Exporter

If you encounter issues with the OTLP Exporter, use the following troubleshooting steps to help diagnose and resolve common problems.

==== Connection failures to the OTLP endpoint

If you are unable to establish a connection to the OTLP endpoint, check the following:

.Procedure 

- Verify the `endpoint` parameter: ensure that the `endpoint` field is correctly configured with the correct OTLP gRPC endpoint. If using `https://`, transport security is enabled. For plain gRPC, omit the `https://` prefix.
+
- Check network connectivity: ensure the OpenTelemetry Collector can reach the specified OTLP endpoint. Test the connection from the host machine to confirm there are no network issues.

==== Authentication or TLS issues

If you are experiencing authentication or TLS errors, consider the following:

.Procedure 

- TLS certificate configuration: ensure the `tls` configuration is correct. This includes providing valid paths to TLS certificates (`tls.cert_file`, `tls.key_file`, `tls.ca_file`) if client-side TLS is enabled.
+
- Check `tls.insecure` and `tls.insecure_skip_verify`: if you need to disable TLS or certificate verification (e.g., for testing), set `tls.insecure` or `tls.insecure_skip_verify` to `true`. Ensure that these options match your security requirements.
+
- Validate `tls.server_name_override`: if you are overriding the virtual host name, ensure that `tls.server_name_override` is set correctly. Mismatched host names may result in failed connections.

==== High latency or message drops

If you experience high latency or message drops, review the following:

.Procedure 

- Increase `sending_queue.queue_size`: if the queue is filling up quickly, increasing `sending_queue.queue_size` can help handle a larger volume of telemetry data. Ensure `sending_queue.enabled` is set to `true`.
+
- Adjust `retry_on_failure` settings: check the `retry_on_failure` configuration. Ensure that the retry intervals (`initial_interval`, `max_interval`) are appropriate for your use case. Prolonged backoff may cause high latency.
+
- Optimize `compression`: use an appropriate compression algorithm. For large payloads, compression methods like `gzip` or `zstd` can reduce the size of data and improve transmission times. Ensure the `compression` field is correctly set.


[id="otlp-http-exporter_{context}"]
== OTLP HTTP Exporter

The OTLP HTTP Exporter exports traces and metrics by using the OpenTelemetry protocol (OTLP).

.OpenTelemetry Collector custom resource with an enabled OTLP Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      otlphttp:
        endpoint: http://tempo-ingester:4318 # <1>
        tls:
          ca_file: ca.pem
          cert_file: cert.pem
          key_file: key.pem
          insecure: false
          insecure_skip_verify: false
          reload_interval: 1h
          server_name_override: ""
        headers:
          X-Scope-OrgID: "dev" # <2>
        disable_keep_alives: false
        write_buffer_size: 524288
        timeout: 30s
        encoding: proto
        compression: gzip
    service:
      pipelines:
        traces:
          exporters: [otlphttp]
        metrics:
          exporters: [otlphttp]
# ...
----
<1> In this example, we are exporting traces to a Tempo instance.
<2> This will set the "X-Scope-OrgID" header in the exported telemetry data. `X-Scope-OrgID` header is used to identify the tenant.

.Parameters used by the OTLP HTTP Exporter
[options="header"]
[cols="a,a,a"]
|===
|Parameter |Description |Default

|`endpoint`
|The OTLP HTTP endpoint. If the `https://` scheme is used, client transport security is enabled and overrides the `insecure` setting in `tls`.
|N/A

|`tls`
|The client-side TLS configuration, defining paths to TLS certificates.
|N/A

|`tls.insecure`
|Disables client transport security when set to `true`.
|`false`

|`tls.insecure_skip_verify`
|Skips verifying the certificate when set to `true`.
|`false`

|`tls.reload_interval`
|Specifies the time interval at which the certificate is reloaded. Accepts valid units of time such as `ns`, `us`, `ms`, `s`, `m`, and `h`.
|N/A

|`tls.server_name_override`
|Overrides the virtual host name of authority such as the authority header field in requests. Useful for testing.
|N/A

|`headers`
|Headers sent in every HTTP request.
|N/A

|`disable_keep_alives`
|If `true`, disables HTTP keep-alives. It will only use the connection to the server for a single HTTP request.
|`false`

|`write_buffer_size`
|The size of the write buffer in bytes.
|`524288`

|`timeout`
|HTTP request time limit.
|`30s`

|`encoding`
|The encoding to use for the messages. Must be `proto` or `json`.
|`proto`

|`compression`
|Compression type to use. Supported values: `gzip`, `snappy`, `zstd`, and `none`.
|`gzip`
|===


=== Troubleshooting the OTLP HTTP Exporter

==== HTTP connection failures

If the OTLP HTTP Exporter is unable to connect to the specified endpoint, review the following:

.Procedure

- Check the `endpoint`: ensure that the `endpoint` field is correctly configured. If you're using `https://`, ensure that the appropriate certificates are provided and client transport security is properly configured.
+
- Verify network connectivity: test network connectivity between the OpenTelemetry Collector and the OTLP HTTP endpoint. Ensure that no firewalls or proxies are blocking the connection.

==== TLS or certificate issues

If you encounter TLS errors or certificate verification failures, consider the following:

.Procedure

- Check `tls.insecure` and `tls.insecure_skip_verify`: if you want to disable TLS or certificate verification for testing purposes, ensure that `tls.insecure` is set to `true` or `tls.insecure_skip_verify` is enabled.
+
- Verify certificate paths: ensure that the `ca_file`, `cert_file`, and `key_file` paths are correctly specified. If these files are missing or incorrect, the connection will fail.

- Certificate reloading: if you are using certificate reloading, confirm that `tls.reload_interval` is set correctly, and verify that certificates are being updated as expected.

==== High latency or performance issues

If you experience performance issues, consider these optimizations:

.Procedure

- Compression settings: ensure that `compression` is appropriately set. Using `gzip` or other compression methods can reduce message size and improve transmission speeds. However, excessive compression can also add overhead.
+
- Increase `write_buffer_size`: the `write_buffer_size` parameter controls how much data can be buffered before sending. If the buffer is too small, it can lead to frequent flushes, which can degrade performance.
+
- Tune the timeout setting: if HTTP requests are timing out, try increasing the `timeout` value from the default `30s` to a longer duration to give requests more time to complete.

==== Incorrect headers sent in requests

If custom headers (like `X-Scope-OrgID`) are missing or incorrect, check the following:

.Procedure

- Verify the `headers` configuration: ensure that custom headers are correctly set in the `headers` field. The headers should be formatted as key-value pairs (e.g., `X-Scope-OrgID: "dev"`).
+
- Confirm the correct use of header fields: if using headers for authentication or tenant identification, ensure that they are accurately formatted and accepted by the receiving server.

==== Timeout or keep-alive issues

If you're experiencing connection timeout or keep-alive problems, check the following:

.Procedure

- Check `disable_keep_alives`: ensure that `disable_keep_alives` is set to `false` if you want to maintain persistent connections to the server. Disabling keep-alives may cause higher latency due to the need to re-establish connections for each request.
+
- Tune the `timeout` parameter: if the exporter is timing out too quickly, increase the `timeout` value. The default is `30s`, but you can extend this to accommodate slower networks or longer request processing times.


[id="debug-exporter_{context}"]
== Debug Exporter

The Debug Exporter prints traces and metrics to the standard output.

.OpenTelemetry Collector custom resource with an enabled Debug Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      debug:
        verbosity: detailed
        sampling_initial: 5
        sampling_thereafter: 200
    service:
      pipelines:
        traces:
          exporters: [debug]
        metrics:
          exporters: [debug]
# ...
----

.Parameters used by the Debug Exporter
[options="header"]
[cols="a,a,a"]
|===
|Parameter |Description |Default

|`verbosity`
|Log output verbosity. Valid values are `detailed`, `normal` and `basic`.
|`basic`

|`sampling_initial`
|Number of messages initially logged each second.
|2

|`sampling_thereafter`
|Sampling rate after the initial messages are logged. The default value of 1 means that sampling is disabled.
|1

|`use_internal_logger`
|Uses the collector's internal logger for output.
|true

|===

[id="prometheus-exporter_{context}"]
== Prometheus Exporter

The Prometheus Exporter exports metrics in the Prometheus or OpenMetrics formats.

:FeatureName: The Prometheus Exporter
include::snippets/technology-preview.adoc[]

.OpenTelemetry Collector custom resource with an enabled Prometheus Exporter
[source,yaml]
----
# ...
  ports:
  - name: promexporter # <1>
    port: 8889
    protocol: TCP
  config: |
    exporters:
      prometheus:
        endpoint: 0.0.0.0:8889 # <2>
        tls: # <3>
          ca_file: ca.pem
          cert_file: cert.pem
          key_file: key.pem
        namespace: prefix # <4>
        const_labels: # <5>
          label1: value1
        enable_open_metrics: true # <6>
        resource_to_telemetry_conversion: # <7>
          enabled: true
        metric_expiration: 180m # <8>
        add_metric_suffixes: false # <9>
    service:
      pipelines:
        metrics:
          exporters: [prometheus]
# ...
----
<1> Expose the metrics in the `8889` port.
<2> The network endpoint where the metrics are exposed.
<3> The server-side TLS configuration. Defines paths to TLS certificates.
<4> If set, exports metrics under the provided value. No default.
<5> Key-value pair labels that are applied for every exported metric. No default.
<6> If `true`, metrics are exported using the OpenMetrics format. Exemplars are only exported in the OpenMetrics format and only for histogram and monotonic sum metrics such as `counter`. Disabled by default.
<7> If `enabled` is `true`, all the resource attributes are converted to metric labels by default. Disabled by default.
<8> Defines how long metrics are exposed without updates. The default is `5m`.
<9> Adds the metrics types and units suffixes. Must be disabled if the monitor tab in Jaeger console is enabled. The default is `true`.

[id="prometheus-remote-write-exporter_{context}"]
== Prometheus Remote Write Exporter

The Prometheus Remote Write Exporter exports metrics to compatible back ends.

:FeatureName: The Prometheus Remote Write Exporter
include::snippets/technology-preview.adoc[]

.OpenTelemetry Collector custom resource with an enabled Prometheus Remote Write Exporter
[source,yaml]
----
# ...
  config: |
    exporters:
      prometheusremotewrite:
        endpoint: "https://my-prometheus:7900/api/v1/push" # <1>
        tls: # <2>
          ca_file: ca.pem
          cert_file: cert.pem
          key_file: key.pem
        target_info: true # <3>
        export_created_metric: true # <4>
        max_batch_size_bytes: 3000000 # <5>
        retry_on_failure: # <6>
          enabled: true
          initial_interval: 5s # <7>
          max_interval: 30s # <8>
          max_elapsed_time: 300s # <9>
        remote_write_queue:  # <10>
          enabled: true
          queue_size: 1000 # <11>
        timeout: 5s # <12>
    service:
      pipelines:
        metrics:
          exporters: [prometheusremotewrite]
# ...
----
<1> Endpoint for sending the metrics.
<2> Server-side TLS configuration. Defines paths to TLS certificates.
<3> When set to `true`, creates a `target_info` metric for each resource metric.
<4> When set to `true`, exports a `_created` metric for the Summary, Histogram, and Monotonic Sum metric points.
<5> Maximum size of the batch of samples that is sent to the remote write endpoint. Exceeding this value results in batch splitting. The default value is `3000000`, which is approximately 2.861 megabytes.
<6> Settings for the retry mechanism. Enabled by default.
<7> Time to wait after the first failure before retrying. Default `5s`.
<8> Upper bound on backoff. Default `30s`.
<9> Is the maximum amount of time spent trying to send a batch. Default is `300s`. `0` means to never stop the retries.
<10> Settings for the remote write sending queue. Enabled by default.
<11> Number of OTLP metrics that can be queued. Default is `10000`.
<12> Time to wait per individual attempt to send data. Default `5s`.

[WARNING]
====
* This exporter drops non-cumulative monotonic, histogram, and summary OTLP metrics.

* You must enable the `--web.enable-remote-write-receiver` feature flag on the remote Prometheus instance. Without it, pushing the metrics to the instance using this exporter fails.
====


[role="_additional-resources"]
[id="additional-resources_otel-collector-exporters_{context}"]
== Additional resources
* link:https://opentelemetry.io/docs/specs/otlp/[OpenTelemetry Protocol (OTLP) documentation]
